{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NTN test 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7ntlmrheux",
        "colab_type": "code",
        "outputId": "006b9d42-8e3b-498b-ba7a-33ba9717f02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "!pip install keras==2.2.5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.16.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed keras-2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY7CPhUrhZSz",
        "colab_type": "code",
        "outputId": "e20daf3d-7495-476f-8fad-b12edc84b5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!rm -rf keras-neural-tensor-layer && git clone https://github.com/LanceNorskog/keras-neural-tensor-layer.git\n",
        "%cd keras-neural-tensor-layer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-neural-tensor-layer'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 41 (delta 0), reused 1 (delta 0), pack-reused 38\u001b[K\n",
            "Unpacking objects: 100% (41/41), done.\n",
            "/content/keras-neural-tensor-layer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsW24yC3i4-R",
        "colab_type": "code",
        "outputId": "7dc95d81-7a44-43de-83bb-270cdecac2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "\n",
        "from neural_tensor_layer import NeuralTensorLayer\n",
        "\n",
        "\n",
        "def get_data():\n",
        "  digits = load_digits()\n",
        "  dig1 = []\n",
        "  dig2 = []\n",
        "  label = []\n",
        "  n = 0\n",
        "  for i in range(digits.data.shape[0]):\n",
        "    for j in range(digits.data.shape[0]):\n",
        "        n = n + 1\n",
        "        if n % 30 == 0: \n",
        "            if digits.target[i] != digits.target[j]:\n",
        "                dig1.append(digits.data[i])\n",
        "                dig2.append(digits.data[j])\n",
        "                if digits.target[i] > digits.target[j]:\n",
        "                    label.append(1.0)\n",
        "                else:\n",
        "                    label.append(0.0)\n",
        "  count = len(dig1)\n",
        "  print('samples: ', count)\n",
        "  (train_i, test_i, _, _) = train_test_split(np.arange(count, dtype='int32'), np.arange(count, dtype='int32'))\n",
        "  print(train_i[0:10])\n",
        "  print(test_i[0:10])\n",
        "  dig1 = np.asarray(dig1, dtype='float32')\n",
        "  dig2 = np.asarray(dig2, dtype='float32')\n",
        "  label = np.asarray(label, dtype='float32')\n",
        "  return dig1[train_i], dig2[train_i], label[train_i], dig1[test_i], dig2[test_i], label[test_i]\n",
        "\n",
        "X1_train,X2_train,Y_train,X1_test,X2_test,Y_test = get_data()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "samples:  96539\n",
            "[30558 39163 63065 52681 31889 64728 32332 69743 32782 56510]\n",
            "[31501 13261 44323 18686 14726 46260 70509 26680 26794 11284]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGTQfjO6kg1L",
        "colab_type": "code",
        "outputId": "69e812ba-cbb4-4400-9d94-8de00431d3c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "\n",
        "if True:\n",
        "  input1 = Input(shape=(64,), dtype='float32')\n",
        "  input2 = Input(shape=(64,), dtype='float32')\n",
        "  btp = NeuralTensorLayer(output_dim=32, input_dim=64)([input1, input2])\n",
        "\n",
        "  p = Dense(units=1)(btp)\n",
        "  model = Model(inputs=[input1, input2], outputs=[p])\n",
        "\n",
        "  adam = Adam()\n",
        "  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  history = model.fit([X1_train, X2_train], Y_train, \n",
        "            validation_data=[[X1_test, X2_test], Y_test],\n",
        "            epochs=10, batch_size=32, verbose=2)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            (None, 64)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, 64)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "neural_tensor_layer_5 (NeuralTe (None, 32)           135232      input_9[0][0]                    \n",
            "                                                                 input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            33          neural_tensor_layer_5[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 135,265\n",
            "Trainable params: 135,265\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 72404 samples, validate on 24135 samples\n",
            "Epoch 1/10\n",
            " - 35s - loss: 5.0776 - binary_accuracy: 0.3435 - val_loss: 4.4559 - val_binary_accuracy: 0.3889\n",
            "Epoch 2/10\n",
            " - 33s - loss: 4.1173 - binary_accuracy: 0.4062 - val_loss: 6.1951 - val_binary_accuracy: 0.4173\n",
            "Epoch 3/10\n",
            " - 33s - loss: 2.9955 - binary_accuracy: 0.4518 - val_loss: 2.6419 - val_binary_accuracy: 0.4615\n",
            "Epoch 4/10\n",
            " - 33s - loss: 2.2873 - binary_accuracy: 0.4746 - val_loss: 1.8842 - val_binary_accuracy: 0.4822\n",
            "Epoch 5/10\n",
            " - 33s - loss: 1.4691 - binary_accuracy: 0.4947 - val_loss: 1.0350 - val_binary_accuracy: 0.5054\n",
            "Epoch 6/10\n",
            " - 33s - loss: 0.8443 - binary_accuracy: 0.5001 - val_loss: 0.7069 - val_binary_accuracy: 0.5093\n",
            "Epoch 7/10\n",
            " - 33s - loss: 0.6994 - binary_accuracy: 0.5020 - val_loss: 0.6944 - val_binary_accuracy: 0.5021\n",
            "Epoch 8/10\n",
            " - 33s - loss: 0.6945 - binary_accuracy: 0.5015 - val_loss: 0.6932 - val_binary_accuracy: 0.5037\n",
            "Epoch 9/10\n",
            " - 33s - loss: 0.6954 - binary_accuracy: 0.5013 - val_loss: 0.6952 - val_binary_accuracy: 0.5037\n",
            "Epoch 10/10\n",
            " - 33s - loss: 0.6959 - binary_accuracy: 0.5019 - val_loss: 0.6970 - val_binary_accuracy: 0.5014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az4dQB1r9_qG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "71001eff-3265-45ad-a52c-1e8c1c4ccc97"
      },
      "source": [
        "\n",
        "plt.figure()\n",
        "metric_names = ['loss', 'binary_accuracy']\n",
        "if history != None:\n",
        "  # summarize history for accuracy\n",
        "  for m in metric_names:\n",
        "      #plt.plot(history.history[m])\n",
        "      plt.plot(history.history['val_' + m])\n",
        "  plt.title('model accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  sname = []\n",
        "  for m in metric_names:\n",
        "      sname.append('{}={:01.3f}'.format(m, history.history['val_' + m][-1]))\n",
        "  plt.legend(sname, loc='lower right')\n",
        "  plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6d2690bbe9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmetric_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6NV-8R2kmuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if True:\n",
        "  score = model.evaluate([X1_test, X2_test], Y_test, batch_size=64)\n",
        "  print('score: ', str(score))\n",
        "  print()\n",
        "\n",
        "  #print(K.get_value(model.layers[2].W))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZUyKxGjlFBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}