{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NTN good tf2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5UqxFSK9mkb",
        "colab_type": "code",
        "outputId": "1a44eae5-30a6-4b5a-f8a2-acfb4a01dc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#!pip install -q keras==2.3.0\n",
        "%tensorflow_version 2.x\n",
        "try:\n",
        "  import tensorflow.compat.v2 as tf\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "#import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(tf.version.VERSION)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n",
            "2.0.0\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmYoANlzr0t_",
        "colab_type": "code",
        "outputId": "7f6bb20d-2c60-4a36-8a31-4a959b9c7c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "#!apt-get install graphviz\n",
        "#!pip install graphviz\n",
        "!pip uninstall -y hiddenlayer\n",
        "!pip install git+https://github.com/LanceNorskog/hiddenlayer.git\n",
        "import hiddenlayer as hl\n",
        "import hiddenlayer.transforms as ht\n",
        "from google.colab import files"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling hiddenlayer-0.2:\n",
            "  Successfully uninstalled hiddenlayer-0.2\n",
            "Collecting git+https://github.com/LanceNorskog/hiddenlayer.git\n",
            "  Cloning https://github.com/LanceNorskog/hiddenlayer.git to /tmp/pip-req-build-u3ala0lf\n",
            "  Running command git clone -q https://github.com/LanceNorskog/hiddenlayer.git /tmp/pip-req-build-u3ala0lf\n",
            "Building wheels for collected packages: hiddenlayer\n",
            "  Building wheel for hiddenlayer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hiddenlayer: filename=hiddenlayer-0.2-cp36-none-any.whl size=19831 sha256=f9893b6f51af622c0af8615619b7d1945e014adddb9843fbb889a66aa55f7eb8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vbticf5t/wheels/07/b1/ab/561eb5cc54236e7e06f4071b36f1265fce591196717cec58f6\n",
            "Successfully built hiddenlayer\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "hiddenlayer"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMIxSUKEfB1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read sklearn image set and:\n",
        "# 1) choose a subset of image pairs\n",
        "# 2) generate boolean values for \"same digit\" and \"digit less than digit\"\n",
        "def get_data(num_samples=100000):\n",
        "  digits = load_digits()\n",
        "  num_images = digits.data.shape[0]\n",
        "    \n",
        "  # create pairs of all images VS all images\n",
        "  num_pairs = num_images * num_images\n",
        "  row, col = np.indices((num_images, num_images))\n",
        "  pair1, pair2 = row.reshape(num_pairs), col.reshape(num_pairs)\n",
        "    \n",
        "  # randomize image pairs and possibly choose a subset\n",
        "  scramble = np.arange(num_pairs, dtype='int32')\n",
        "  np.random.shuffle(scramble)\n",
        "  pair1 = pair1[scramble]\n",
        "  pair2 = pair2[scramble]\n",
        "  if num_samples < num_pairs:\n",
        "    pair1 = pair1[0:num_samples]\n",
        "    pair2 = pair2[0:num_samples]\n",
        "    num_pairs = num_samples\n",
        "\n",
        "  # prepare actual images for input\n",
        "  input1 = digits.data[pair1] / 16.0\n",
        "  input2 = digits.data[pair2] / 16.0\n",
        "\n",
        "  # Are images of same digit? Is one digit less than the other?\n",
        "  # (2 images, [0, 1])\n",
        "  left = digits.target[pair1]\n",
        "  right = digits.target[pair2]   \n",
        "  output = np.reshape(np.transpose([left == right, left < right], (1, 0)), (num_pairs, 2))\n",
        "    \n",
        "  return input1, input2, output, left, right\n",
        "\n",
        "X1_train,X2_train,Y_train, left, right = get_data(num_samples=100000)\n",
        "X1_val = X1_train[90000:]\n",
        "X2_val = X2_train[90000:]\n",
        "Y_val = Y_train[90000:]\n",
        "X1_train = X1_train[:90000]\n",
        "X2_train = X2_train[:90000]\n",
        "Y_train = Y_train[:90000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIK_YpBq93Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.python.keras.engine.base_layer import Layer\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "class NeuralTensorDiagLayer(Layer):\n",
        "  def __init__(self, output_dim, activation=K.tanh, collector=K.mean, \n",
        "               feedforward=True, bias=True, ntn=True, siamese=True, **kwargs):\n",
        "    self.output_dim = output_dim #k\n",
        "    self.activation = activation\n",
        "    self.collector = collector\n",
        "    self.feedforward = feedforward\n",
        "    self.bias = bias\n",
        "    self.ntn = ntn\n",
        "    self.siamese = siamese\n",
        "    super(NeuralTensorDiagLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    assert input_shape[0][-1] == input_shape[1][-1]\n",
        "    mean = 0.0\n",
        "    std = 1.0\n",
        "    # W : k*d\n",
        "    k = self.output_dim\n",
        "    d = input_shape[0][-1]\n",
        "    self.input_dim = d\n",
        "\n",
        "    # w_init = tf.initializers.truncated_normal(mean=mean, stddev=2*std)\n",
        "    # w_init =  tf.compat.v2.initializers.TruncatedNormal(mean=mean, stddev=2*std)\n",
        "    #v_init = tf.initializers.truncated_normal(mean=mean, stddev=2*std)\n",
        "    w_init = tf.initializers.glorot_uniform\n",
        "    v_init = tf.initializers.glorot_uniform\n",
        "    b_init = tf.initializers.zeros\n",
        "    if self.ntn:\n",
        "        self.W = self.add_weight(shape=(d, k), \n",
        "                             initializer=w_init,\n",
        "                             trainable=True,\n",
        "                             name='W')\n",
        "        print('self.W:', self.W)\n",
        "    if self.siamese:\n",
        "        self.V = self.add_weight(shape=(d, k), \n",
        "                             initializer=v_init,\n",
        "                             trainable=True,\n",
        "                             name='V')\n",
        "    elif self.feedforward:\n",
        "        self.V = self.add_weight(shape=(2*d, k), \n",
        "                             initializer=v_init,\n",
        "                             trainable=True,\n",
        "                             name='V')\n",
        "    if self.bias:\n",
        "        self.b = self.add_weight(shape=(k), initializer=b_init, trainable=True, name='b')\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    if type(inputs) is not list or len(inputs) != 2:\n",
        "      raise Exception('NTNDiagLayer must be called on a list of tensors '\n",
        "                      '(at least 2). Got: ' + str(inputs))\n",
        "    k = self.output_dim\n",
        "    e1 = inputs[0]\n",
        "    e2 = inputs[1]\n",
        "    if self.siamese:\n",
        "        print('sub:', e1 - e2)\n",
        "        feed_forward_product = K.dot(e1 - e2, self.V)\n",
        "        print('ff: ', feed_forward_product)\n",
        "    elif self.feedforward:\n",
        "        feed_forward_product = K.dot(K.concatenate([e1,e2]), self.V)\n",
        "        print('ff: ', feed_forward_product)\n",
        "    if not self.ntn:\n",
        "        result = feed_forward_product + self.b\n",
        "        if self.activation:\n",
        "            result = self.activation(result)\n",
        "        return result\n",
        "\n",
        "    e1 = K.flatten(inputs[0])\n",
        "    e2 = K.flatten(inputs[1])\n",
        "    e1 = K.tile(e1, k)\n",
        "    e2 = K.tile(e2, k)\n",
        "    print('e1:', e1)\n",
        "    e1 = K.reshape(e1, shape=(-1, k, self.input_dim))\n",
        "    e2 = K.reshape(e2, shape=(-1, k, self.input_dim))\n",
        "    print('e1:', e1)\n",
        "    # x0 = e1 * self.W\n",
        "    # print('x0:', x0)\n",
        "    # x1 = x0 * e2\n",
        "    # print('x1:', x1)\n",
        "    #x0 = K.dot(e2[...], self.W[...])\n",
        "    #print('x0:', x0)\n",
        "    #x = K.dot(e1, x0)\n",
        "    #print('x:', x)\n",
        "    x0 = K.dot(e1, self.W[...])\n",
        "    print('x0:', x0)\n",
        "    x = K.dot(e1, x0)\n",
        "    print('x:', x)\n",
        "\n",
        "    #y = self.collector(x, axis=-1, keepdims=True)\n",
        "    #y = x\n",
        "    #print('y:', y)\n",
        "    #z = K.squeeze(y, axis=-1)\n",
        "    #print('z:', z)\n",
        "    stacked = x \n",
        "    print('o1: ', stacked)\n",
        "    #stacked = K.expand_dims(stacked, axis=0)\n",
        "    print('o2: ', stacked)\n",
        "    if (self.feedforward or self.siamese) and self.bias:\n",
        "        result = stacked + feed_forward_product + self.b\n",
        "    elif (self.feedforward or self.siamese):\n",
        "        result = stacked + feed_forward_product  \n",
        "    elif self.bias:\n",
        "        result = stacked + self.b\n",
        "    elif not self.ntn:\n",
        "        result = feedforward + self.b\n",
        "    else:\n",
        "        retult = None\n",
        "    if self.activation:\n",
        "        result = self.activation(result)\n",
        "        \n",
        "    print('result: ', result)\n",
        "    print(\"call() finished\")\n",
        "    return result\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    batch_size = input_shape[0][0]\n",
        "    return (batch_size, self.output_dim)\n",
        "\n",
        "  # not sure if valid when not base types\n",
        "  def get_config(self):\n",
        "    config = super(NeuralTensorDiagLayer, self).get_config()\n",
        "    config.update({'output_dim': self.output_dim})\n",
        "    config.update({'activation': self.activation})\n",
        "    config.update({'collector': self.collector})\n",
        "    config.update({'bias': self.bias})\n",
        "    config.update({'feedforward': self.feedforward})\n",
        "    return config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtHE9f7l_p_G",
        "colab_type": "code",
        "outputId": "538e2ecd-a478-4506-c2c4-4572a80b943f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  activ = K.tanh\n",
        "  collect = K.mean\n",
        "  input1 = Input(shape=(64,), dtype='float32')\n",
        "  input2 = Input(shape=(64,), dtype='float32')\n",
        "  i1 = input1\n",
        "  i2 = input2\n",
        "  squishify = Dense(24) #, activation='tanh')\n",
        "  i1 = squishify(input1)\n",
        "  i2 = squishify(input2)\n",
        "#   i1 = Dense(24, activation='tanh')(i1)\n",
        "#   i2 = Dense(24, activation='tanh')(i2)\n",
        "  btp = NeuralTensorDiagLayer(output_dim=32, \n",
        "                            activation=K.tanh, collector=K.mean, \n",
        "                            feedforward=False, siamese=False, ntn=True)([i1, i2])\n",
        "  #last = Dense(units=16, activation='tanh')(btp)\n",
        "  p = Dense(units=2, activation='sigmoid')(btp)\n",
        "    \n",
        "  model = Model(inputs=[input1, input2], outputs=[p])\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  early = EarlyStopping(monitor='val_loss', verbose=1, patience=5)\n",
        "  model.fit([X1_train, X2_train], Y_train, \n",
        "            nb_epoch=50, batch_size=8\n",
        "            , validation_split=0.1\n",
        "            , callbacks=[early]\n",
        "            , shuffle=True)\n",
        "  score = model.evaluate([X1_val, X2_val], Y_val, batch_size=16)\n",
        "  print(score)\n",
        "\n",
        "  transforms = [\n",
        "            # Build basic folds first\n",
        "            # ht.Fold(\\\"Mul > Add > Sum\\\", \\\"MulAddSum\\\")\n",
        "            # Display fully-connected layers differently\n",
        "            ht.Prune(\"IsVariableInitialized\"),\n",
        "            # Fold repeated nodes\n",
        "            ht.FoldDuplicates()\n",
        "            ]\n",
        "  K.set_learning_phase(1)\n",
        "  hl_graph = hl.build_graph(g) #, transforms=transforms)\n",
        "  hl_graph.theme = hl.graph.THEMES['blue'].copy()\n",
        "  hl_graph.save('/tmp/filediag.pdf')  # Display graph view\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "self.W: <tf.Variable 'neural_tensor_diag_layer/W:0' shape=(24, 32) dtype=float32>\n",
            "e1: Tensor(\"neural_tensor_diag_layer/Tile:0\", shape=(None,), dtype=float32)\n",
            "e1: Tensor(\"neural_tensor_diag_layer/Reshape_2:0\", shape=(None, 32, 24), dtype=float32)\n",
            "x0: Tensor(\"neural_tensor_diag_layer/Reshape_6:0\", shape=(None, 32, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-07da77888009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   btp = NeuralTensorDiagLayer(output_dim=32, \n\u001b[1;32m     19\u001b[0m                             \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                             feedforward=False, siamese=False, ntn=True)([i1, i2])\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0;31m#last = Dense(units=16, activation='tanh')(btp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-32-43234e3d62f6>:91 call  *\n        x = K.dot(e1, x0)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/backend.py:1699 dot\n        math_ops.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/util/dispatch.py:180 wrapper\n        return target(*args, **kwargs)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/math_ops.py:2765 matmul\n        a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/gen_math_ops.py:6136 mat_mul\n        name=name)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/op_def_library.py:793 _apply_op_helper\n        op_def=op_def)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/ops.py:3360 create_op\n        attrs, op_def, compute_device)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/ops.py:3429 _create_op_internal\n        op_def=op_def)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/ops.py:1773 __init__\n        control_input_ops)\n    /tensorflow-2.0.0/python3.6/tensorflow_core/python/framework/ops.py:1613 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 24 and 32 for 'neural_tensor_diag_layer/MatMul_1' (op: 'MatMul') with input shapes: [?,24], [32,?].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNjcmbEGAKK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('val #:', X1_val.shape[0])\n",
        "score = model.evaluate([X1_val, X2_val], Y_val, batch_size=16)\n",
        "\n",
        "files.download('/tmp/filediag.pdf')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iepFXJqkBFCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}