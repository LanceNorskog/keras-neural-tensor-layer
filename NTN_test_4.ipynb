{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NTN test 4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7ntlmrheux",
        "colab_type": "code",
        "outputId": "2e2b8407-e883-4a7e-b7c3-62ba9bcea9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "!pip install keras==2.2.5\n",
        "!apt-get install graphviz \n",
        "!pip install graphviz\n",
        "!pip install git+https://github.com/waleedka/hiddenlayer.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.16.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.12.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Collecting git+https://github.com/waleedka/hiddenlayer.git\n",
            "  Cloning https://github.com/waleedka/hiddenlayer.git to /tmp/pip-req-build-rtlw4tlu\n",
            "  Running command git clone -q https://github.com/waleedka/hiddenlayer.git /tmp/pip-req-build-rtlw4tlu\n",
            "Requirement already satisfied (use --upgrade to upgrade): hiddenlayer==0.2 from git+https://github.com/waleedka/hiddenlayer.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: hiddenlayer\n",
            "  Building wheel for hiddenlayer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hiddenlayer: filename=hiddenlayer-0.2-cp36-none-any.whl size=19746 sha256=e607497eec027e7863ea1da042675da065f8ed7420a0fdfa614a825214d86814\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dasch10_/wheels/49/bc/d1/938073704abdd049b3e4cdc6811c8f468d69fb5eecc6e01748\n",
            "Successfully built hiddenlayer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY7CPhUrhZSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -rf keras-neural-tensor-layer\n",
        "#!&& git clone https://github.com/LanceNorskog/keras-neural-tensor-layer.git\n",
        "#%cd keras-neural-tensor-layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsW24yC3i4-R",
        "colab_type": "code",
        "outputId": "68c01523-6b5c-415c-e550-397c53a3ed7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import hiddenlayer as hl\n",
        "import hiddenlayer.transforms as ht\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#from ntn_diag import NeuralTensorDiagLayer\n",
        "\n",
        "def get_data2(num_samples=100000):\n",
        "  digits = load_digits()\n",
        "  # create pairs of all images VS all images\n",
        "  num_pairs = digits.data.shape[0] * digits.data.shape[0]\n",
        "  pair1 = np.zeros((num_pairs), dtype='int32')\n",
        "  pair2 = np.zeros((num_pairs), dtype='int32')\n",
        "  #pair2 = [0] * num_pairs\n",
        "  print(digits.data.shape[0])\n",
        "  print(digits.data.shape[0] * digits.data.shape[0])\n",
        "  k = 0\n",
        "  # numpy.indices might do this but I can't figure it out!\n",
        "  row, col = np.indices((digits.data.shape[0], digits.data.shape[0]))\n",
        "  print('row.shape: ', row.shape)\n",
        "  pair1 = row.reshape(num_pairs)\n",
        "  pair2 = col.reshape(num_pairs)\n",
        "  #for i in range(digits.data.shape[0]):\n",
        "  #  for j in range(digits.data.shape[0]):\n",
        "  #    pair1[k] = i\n",
        "  #    pair2[k] = j\n",
        "  #    k += 1\n",
        "    \n",
        "  # pick a random subset of image pairs\n",
        "  subset = np.arange(num_pairs, dtype='int32')\n",
        "  np.random.shuffle(subset)\n",
        "  if num_samples < num_pairs:\n",
        "    subset = subset[0:num_samples]\n",
        "    print('subset: ', subset[0:20])\n",
        "    pair1 = pair1[subset]\n",
        "    pair2 = pair2[subset]\n",
        "    num_pairs = num_samples\n",
        "\n",
        "  print(pair1.shape)\n",
        "  print(pair1[0:20])\n",
        "  print(pair2[0:20])\n",
        "\n",
        "  # calculate whether label of image is same, and if is lt\n",
        "  left = digits.target[pair1]\n",
        "  right = digits.target[pair2]\n",
        "  print('left : ', left[0:20])\n",
        "  print('right: ', right[0:20])\n",
        "  eqall = np.asarray(left == right, dtype='float32')\n",
        "  ltall = np.asarray(left < right, dtype='float32')\n",
        "  print('eqall: ', eqall[0:20])\n",
        "  print('ltall: ', ltall[0:20])\n",
        "\n",
        "  # prepare actual images for input\n",
        "  input1 = digits.data[pair1] / 16.0\n",
        "  input2 = digits.data[pair2] / 16.0\n",
        "  print(input1.shape)\n",
        "  print(input2.shape)\n",
        "    \n",
        "  # prepare output of [eq, lt]\n",
        "  output = np.zeros((num_pairs, 2))\n",
        "  output = np.reshape(np.transpose([eqall, ltall], (1, 0)), (num_pairs, 2))\n",
        "    \n",
        "  print(output.shape)\n",
        "  print(output[0:20])\n",
        " \n",
        "  return input1, input2, output\n",
        "\n",
        "\n",
        "def get_data():\n",
        "  digits = load_digits()\n",
        "  dig1 = []\n",
        "  dig2 = []\n",
        "  label = []\n",
        "  for i in range(digits.data.shape[0]):\n",
        "    for j in range(digits.data.shape[0]):\n",
        "        #n = n + 1\n",
        "        #if n % 50 == 0: \n",
        "            if digits.target[i] != digits.target[j]:\n",
        "                dig1.append(digits.data[i])\n",
        "                dig2.append(digits.data[j])\n",
        "                if digits.target[i] > digits.target[j]:\n",
        "                    label.append(1.0)\n",
        "                else:\n",
        "                    label.append(0.0)\n",
        "  count = len(dig1)\n",
        "  print('samples: ', count)\n",
        "  (train_i, test_i, _, _) = train_test_split(np.arange(count, dtype='int32'), np.arange(count, dtype='int32'))\n",
        "  print(train_i[0:10])\n",
        "  print(test_i[0:10])\n",
        "  dig1 = np.asarray(dig1, dtype='float32')/16.0\n",
        "  dig2 = np.asarray(dig2, dtype='float32')/16.0\n",
        "  label = np.asarray(label, dtype='float32')\n",
        "  return dig1[train_i], dig2[train_i], label[train_i], dig1[test_i], dig2[test_i], label[test_i]\n",
        "\n",
        "X1_train,X2_train,Y_train = get_data2(num_samples=100000)\n",
        "\n",
        "print(X1_train[2])\n",
        "print(X2_train[2])\n",
        "print(Y_train[2])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1797\n",
            "3229209\n",
            "row.shape:  (1797, 1797)\n",
            "subset:  [1574080  723949   78706 3020503 1977809 2917572  972177 1204009 2568481\n",
            " 2065361 3114936 2478456 2485516 1951504  730493 2440181 3219356 2362938\n",
            "  741290 2419662]\n",
            "(100000,)\n",
            "[ 875  402   43 1680 1100 1623  541  670 1429 1149 1733 1379 1383 1085\n",
            "  406 1357 1791 1314  412 1346]\n",
            "[1705 1555 1435 1543 1109 1041    0   19  568  608  735  393  265 1759\n",
            "  911 1652  929 1680  926  900]\n",
            "left :  [1 6 7 3 9 6 5 4 4 8 6 9 8 6 0 1 4 7 6 3]\n",
            "right:  [8 0 0 9 6 2 0 9 7 9 3 7 9 9 6 4 4 3 1 4]\n",
            "eqall:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "ltall:  [1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
            "(100000, 64)\n",
            "(100000, 64)\n",
            "(100000, 2)\n",
            "[[0. 1.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 1.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 0.]\n",
            " [0. 0.]\n",
            " [0. 1.]]\n",
            "[0.     0.     0.     0.5625 0.9375 0.75   0.     0.     0.     0.\n",
            " 0.25   0.4375 0.4375 0.875  0.     0.     0.     0.     0.     0.\n",
            " 0.     0.8125 0.1875 0.     0.     0.25   0.5625 0.5    0.625  0.8125\n",
            " 0.0625 0.     0.     0.25   1.     0.9375 1.     1.     0.375  0.\n",
            " 0.     0.     0.     0.     0.875  0.1875 0.     0.     0.     0.\n",
            " 0.     0.5625 0.75   0.     0.     0.     0.     0.     0.     0.6875\n",
            " 0.4375 0.     0.     0.    ]\n",
            "[0.     0.     0.125  0.5625 0.875  0.75   0.     0.     0.     0.\n",
            " 0.75   1.     0.625  0.9375 0.0625 0.     0.     0.25   0.875  0.1875\n",
            " 0.125  0.375  0.375  0.     0.     0.3125 0.4375 0.     0.     0.1875\n",
            " 0.5    0.     0.     0.25   0.4375 0.     0.     0.0625 0.5    0.\n",
            " 0.     0.1875 0.75   0.0625 0.     0.3125 0.5    0.     0.     0.\n",
            " 0.625  0.75   0.4375 0.875  0.1875 0.     0.     0.     0.0625 0.75\n",
            " 1.     0.5    0.     0.    ]\n",
            "[0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_e7hchLa4z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.engine.topology import Layer\n",
        "import scipy.stats as stats\n",
        "\n",
        "class NeuralTensorDiagLayer(Layer):\n",
        "  def __init__(self, output_dim, input_dim=None, **kwargs):\n",
        "    self.output_dim = output_dim #k\n",
        "    self.input_dim = input_dim   #d\n",
        "    if self.input_dim:\n",
        "      kwargs['input_shape'] = (self.input_dim,)\n",
        "    super(NeuralTensorDiagLayer, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    mean = 0.0\n",
        "    std = 1.0\n",
        "    # W : k*d\n",
        "    k = self.output_dim\n",
        "    d = self.input_dim\n",
        "    initial_W_values = stats.truncnorm.rvs(-2 * std, 2 * std, loc=mean, scale=std, size=(k,d))\n",
        "    initial_V_values = stats.truncnorm.rvs(-2 * std, 2 * std, loc=mean, scale=std, size=(2*d,k))\n",
        "    self.W = K.variable(initial_W_values, name='W')\n",
        "    self.V = K.variable(initial_V_values, name='V')\n",
        "    self.b = K.zeros((self.input_dim * 2,), name='b')\n",
        "    self.trainable_weights = [self.W, self.V, self.b]\n",
        "\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    if type(inputs) is not list or len(inputs) != 2:\n",
        "      raise Exception('NTNDiagLayer must be called on a list of tensors '\n",
        "                      '(at least 2). Got: ' + str(inputs))\n",
        "    e1 = inputs[0]\n",
        "    e2 = inputs[1]\n",
        "    #batch_size = K.shape(e1)[0]\n",
        "    #print('batch_size: ', batch_size)\n",
        "    k = self.output_dim\n",
        "    #print('inputs: ', [e1,e2])\n",
        "    feed_forward_product = K.dot(K.concatenate([e1,e2]) + self.b, self.V)\n",
        "    #print('ff: ', feed_forward_product)\n",
        "    #print('d1: ', e1 * self.W[0])\n",
        "    #print('d2: ', e2 * (e1 * self.W[0]))\n",
        "    #print('d3: ', e2 * (e1 * self.W[0]) + self.b)\n",
        "    diag_tensor_products = [] \n",
        "    for i in range(k):\n",
        "      diag_tensor_products.append(K.sum(e2 * (e1 * self.W[i])))\n",
        "    #print('diag.shape: ', K.shape(diag_tensor_products[0]))\n",
        "    #print('o1: ', K.stack(diag_tensor_products))\n",
        "    #print('o2: ', K.reshape(K.concatenate(diag_tensor_products, axis=1), (batch_size, k)))\n",
        "    #print('o3: ', K.reshape(K.concatenate(diag_tensor_products, axis=1), (-1, k)) + feed_forward_product)\n",
        "    result = K.tanh(K.stack(diag_tensor_products) + feed_forward_product)\n",
        "    #print('result: ', result)\n",
        "    return result\n",
        "\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    # print (input_shape)\n",
        "    batch_size = input_shape[0][0]\n",
        "    return (batch_size, self.output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGTQfjO6kg1L",
        "colab_type": "code",
        "outputId": "785c000f-108a-4b1d-e566-64e22bd8cf5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        }
      },
      "source": [
        "!rm -f /tmp/filediag.pdf\n",
        "squish=24\n",
        "squish2=32\n",
        "\n",
        "if True:\n",
        "  input1 = Input(shape=(64,), dtype='float32')\n",
        "  input2 = Input(shape=(64,), dtype='float32')\n",
        "  i1 = Dense(units=squish, activation='relu')(input1)\n",
        "  i2 = Dense(units=squish, activation='relu')(input2)\n",
        "  btp = NeuralTensorDiagLayer(output_dim=squish2, input_dim=squish)([i1, i2])\n",
        "\n",
        "  p = Dense(units=2, activation='sigmoid')(btp)\n",
        "  model = Model(inputs=[input1, input2], outputs=[p])\n",
        "\n",
        "  adam = Adam()\n",
        "  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['binary_accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  # Display graph view\n",
        "  transforms = [\n",
        "    # Build basic folds first\n",
        "    # ht.Fold(\"Mul > Add > Sum\", \"MulAddSum\"),\n",
        "    # Display fully-connected layers differently\n",
        "    ht.Prune(\"IsVariableInitialized\"),\n",
        "    # Fold repeated nodes\n",
        "    ht.FoldDuplicates(),\n",
        "  ]\n",
        "  K.set_learning_phase(1)\n",
        "  hl_graph = hl.build_graph(K.get_session().graph, transforms=transforms)\n",
        "  hl_graph.theme = hl.graph.THEMES[\"blue\"].copy()\n",
        "\n",
        "  #print('graph: ', hl_graph)\n",
        "\n",
        "  hl_graph.save('/tmp/filediag.pdf')  # Display graph view\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0901 02:46:48.967873 140377242236800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0901 02:46:48.982784 140377242236800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0901 02:46:48.990122 140377242236800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0901 02:46:49.211176 140377242236800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0901 02:46:49.221872 140377242236800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0901 02:46:49.228716 140377242236800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0901 02:46:49.254809 140377242236800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0901 02:46:49.347449 140377242236800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/hiddenlayer/tf_builder.py:70: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.remove_training_nodes`\n",
            "W0901 02:46:49.370135 140377242236800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/hiddenlayer/tf_builder.py:108: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 64)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 24)           1560        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 24)           1560        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "neural_tensor_diag_layer_1 (Neu (None, 32)           2352        dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            66          neural_tensor_diag_layer_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 5,538\n",
            "Trainable params: 5,538\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp3TOF2dgImv",
        "colab_type": "code",
        "outputId": "e427d515-16cd-4e78-de8d-dc7069c900ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "!ls -l /tmp/file*.pdf\n",
        "files.download('/tmp/filediag.pdf')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 35287 Sep  1 02:46 /tmp/filediag.pdf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-17a96c0e41c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls -l /tmp/file*.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/filediag.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: NetworkError when attempting to fetch resource."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az4dQB1r9_qG",
        "colab_type": "code",
        "outputId": "23696cb3-98b7-4ba4-f1b1-bb326a8f395b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit([X1_train, X2_train], Y_train, \n",
        "            validation_split=0.2,\n",
        "            callbacks = [EarlyStopping(patience=5)],\n",
        "            epochs=50, batch_size=32, verbose=2)\n",
        "\n",
        "plt.figure()\n",
        "metric_names = ['loss', 'binary_accuracy']\n",
        "if history != None:\n",
        "  # summarize history for accuracy\n",
        "  for m in metric_names:\n",
        "      #plt.plot(history.history[m])\n",
        "      plt.plot(history.history['val_' + m])\n",
        "  plt.title('model accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  sname = []\n",
        "  for m in metric_names:\n",
        "      sname.append('{}={:01.3f}'.format(m, history.history['val_' + m][-1]))\n",
        "  plt.legend(sname, loc='center right')\n",
        "  plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80000 samples, validate on 20000 samples\n",
            "Epoch 1/50\n",
            " - 9s - loss: 0.4955 - binary_accuracy: 0.7475 - val_loss: 0.4140 - val_binary_accuracy: 0.8305\n",
            "Epoch 2/50\n",
            " - 8s - loss: 0.3128 - binary_accuracy: 0.8803 - val_loss: 0.2467 - val_binary_accuracy: 0.9049\n",
            "Epoch 3/50\n",
            " - 7s - loss: 0.2030 - binary_accuracy: 0.9193 - val_loss: 0.1663 - val_binary_accuracy: 0.9367\n",
            "Epoch 4/50\n",
            " - 7s - loss: 0.1354 - binary_accuracy: 0.9488 - val_loss: 0.1093 - val_binary_accuracy: 0.9598\n",
            "Epoch 5/50\n",
            " - 8s - loss: 0.0916 - binary_accuracy: 0.9681 - val_loss: 0.0795 - val_binary_accuracy: 0.9733\n",
            "Epoch 6/50\n",
            " - 8s - loss: 0.0672 - binary_accuracy: 0.9779 - val_loss: 0.0576 - val_binary_accuracy: 0.9819\n",
            "Epoch 7/50\n",
            " - 8s - loss: 0.0518 - binary_accuracy: 0.9835 - val_loss: 0.0495 - val_binary_accuracy: 0.9846\n",
            "Epoch 8/50\n",
            " - 8s - loss: 0.0410 - binary_accuracy: 0.9870 - val_loss: 0.0405 - val_binary_accuracy: 0.9876\n",
            "Epoch 9/50\n",
            " - 8s - loss: 0.0332 - binary_accuracy: 0.9898 - val_loss: 0.0357 - val_binary_accuracy: 0.9888\n",
            "Epoch 10/50\n",
            " - 8s - loss: 0.0273 - binary_accuracy: 0.9917 - val_loss: 0.0274 - val_binary_accuracy: 0.9914\n",
            "Epoch 11/50\n",
            " - 8s - loss: 0.0232 - binary_accuracy: 0.9928 - val_loss: 0.0228 - val_binary_accuracy: 0.9929\n",
            "Epoch 12/50\n",
            " - 8s - loss: 0.0194 - binary_accuracy: 0.9943 - val_loss: 0.0218 - val_binary_accuracy: 0.9929\n",
            "Epoch 13/50\n",
            " - 7s - loss: 0.0161 - binary_accuracy: 0.9950 - val_loss: 0.0179 - val_binary_accuracy: 0.9944\n",
            "Epoch 14/50\n",
            " - 8s - loss: 0.0146 - binary_accuracy: 0.9957 - val_loss: 0.0171 - val_binary_accuracy: 0.9950\n",
            "Epoch 15/50\n",
            " - 8s - loss: 0.0123 - binary_accuracy: 0.9965 - val_loss: 0.0168 - val_binary_accuracy: 0.9947\n",
            "Epoch 16/50\n",
            " - 8s - loss: 0.0110 - binary_accuracy: 0.9968 - val_loss: 0.0137 - val_binary_accuracy: 0.9956\n",
            "Epoch 17/50\n",
            " - 8s - loss: 0.0096 - binary_accuracy: 0.9972 - val_loss: 0.0172 - val_binary_accuracy: 0.9938\n",
            "Epoch 18/50\n",
            " - 8s - loss: 0.0084 - binary_accuracy: 0.9976 - val_loss: 0.0106 - val_binary_accuracy: 0.9966\n",
            "Epoch 19/50\n",
            " - 8s - loss: 0.0073 - binary_accuracy: 0.9980 - val_loss: 0.0110 - val_binary_accuracy: 0.9965\n",
            "Epoch 20/50\n",
            " - 8s - loss: 0.0069 - binary_accuracy: 0.9981 - val_loss: 0.0084 - val_binary_accuracy: 0.9974\n",
            "Epoch 21/50\n",
            " - 8s - loss: 0.0062 - binary_accuracy: 0.9982 - val_loss: 0.0086 - val_binary_accuracy: 0.9975\n",
            "Epoch 22/50\n",
            " - 8s - loss: 0.0053 - binary_accuracy: 0.9986 - val_loss: 0.0079 - val_binary_accuracy: 0.9977\n",
            "Epoch 23/50\n",
            " - 8s - loss: 0.0052 - binary_accuracy: 0.9985 - val_loss: 0.0072 - val_binary_accuracy: 0.9979\n",
            "Epoch 24/50\n",
            " - 8s - loss: 0.0050 - binary_accuracy: 0.9987 - val_loss: 0.0058 - val_binary_accuracy: 0.9982\n",
            "Epoch 25/50\n",
            " - 8s - loss: 0.0043 - binary_accuracy: 0.9989 - val_loss: 0.0074 - val_binary_accuracy: 0.9979\n",
            "Epoch 26/50\n",
            " - 8s - loss: 0.0043 - binary_accuracy: 0.9989 - val_loss: 0.0058 - val_binary_accuracy: 0.9984\n",
            "Epoch 27/50\n",
            " - 8s - loss: 0.0033 - binary_accuracy: 0.9991 - val_loss: 0.0051 - val_binary_accuracy: 0.9985\n",
            "Epoch 28/50\n",
            " - 8s - loss: 0.0039 - binary_accuracy: 0.9989 - val_loss: 0.0094 - val_binary_accuracy: 0.9973\n",
            "Epoch 29/50\n",
            " - 8s - loss: 0.0034 - binary_accuracy: 0.9991 - val_loss: 0.0072 - val_binary_accuracy: 0.9979\n",
            "Epoch 30/50\n",
            " - 7s - loss: 0.0028 - binary_accuracy: 0.9993 - val_loss: 0.0051 - val_binary_accuracy: 0.9987\n",
            "Epoch 31/50\n",
            " - 7s - loss: 0.0036 - binary_accuracy: 0.9990 - val_loss: 0.0056 - val_binary_accuracy: 0.9983\n",
            "Epoch 32/50\n",
            " - 8s - loss: 0.0024 - binary_accuracy: 0.9995 - val_loss: 0.0086 - val_binary_accuracy: 0.9973\n",
            "Epoch 33/50\n",
            " - 8s - loss: 0.0031 - binary_accuracy: 0.9992 - val_loss: 0.0050 - val_binary_accuracy: 0.9986\n",
            "Epoch 34/50\n",
            " - 7s - loss: 0.0025 - binary_accuracy: 0.9993 - val_loss: 0.0049 - val_binary_accuracy: 0.9987\n",
            "Epoch 35/50\n",
            " - 7s - loss: 0.0022 - binary_accuracy: 0.9994 - val_loss: 0.0041 - val_binary_accuracy: 0.9988\n",
            "Epoch 36/50\n",
            " - 8s - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0032 - val_binary_accuracy: 0.9991\n",
            "Epoch 37/50\n",
            " - 8s - loss: 0.0027 - binary_accuracy: 0.9992 - val_loss: 0.0036 - val_binary_accuracy: 0.9989\n",
            "Epoch 38/50\n",
            " - 8s - loss: 0.0016 - binary_accuracy: 0.9996 - val_loss: 0.0042 - val_binary_accuracy: 0.9988\n",
            "Epoch 39/50\n",
            " - 8s - loss: 0.0023 - binary_accuracy: 0.9994 - val_loss: 0.0046 - val_binary_accuracy: 0.9988\n",
            "Epoch 40/50\n",
            " - 8s - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0042 - val_binary_accuracy: 0.9989\n",
            "Epoch 41/50\n",
            " - 8s - loss: 0.0022 - binary_accuracy: 0.9994 - val_loss: 0.0031 - val_binary_accuracy: 0.9990\n",
            "Epoch 42/50\n",
            " - 8s - loss: 0.0016 - binary_accuracy: 0.9996 - val_loss: 0.0038 - val_binary_accuracy: 0.9989\n",
            "Epoch 43/50\n",
            " - 8s - loss: 0.0018 - binary_accuracy: 0.9995 - val_loss: 0.0053 - val_binary_accuracy: 0.9981\n",
            "Epoch 44/50\n",
            " - 8s - loss: 0.0017 - binary_accuracy: 0.9995 - val_loss: 0.0030 - val_binary_accuracy: 0.9993\n",
            "Epoch 45/50\n",
            " - 8s - loss: 0.0017 - binary_accuracy: 0.9995 - val_loss: 0.0045 - val_binary_accuracy: 0.9989\n",
            "Epoch 46/50\n",
            " - 8s - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0034 - val_binary_accuracy: 0.9991\n",
            "Epoch 47/50\n",
            " - 7s - loss: 0.0013 - binary_accuracy: 0.9997 - val_loss: 0.0042 - val_binary_accuracy: 0.9989\n",
            "Epoch 48/50\n",
            " - 8s - loss: 0.0016 - binary_accuracy: 0.9996 - val_loss: 0.0047 - val_binary_accuracy: 0.9986\n",
            "Epoch 49/50\n",
            " - 8s - loss: 0.0011 - binary_accuracy: 0.9997 - val_loss: 0.0033 - val_binary_accuracy: 0.9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZUyKxGjlFBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}